{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c5a94671",
      "metadata": {
        "id": "c5a94671"
      },
      "source": [
        "<h1>\n",
        "\tThe Annotated Diffusion Model\n",
        "</h1>\n",
        "\n",
        "\n",
        "<div class=\"author-card\">\n",
        "    <a href=\"/nielsr\">\n",
        "        <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/48327001?v=4\" width=\"100\" title=\"Gravatar\">\n",
        "        <div class=\"bfc\">\n",
        "            <code>nielsr</code>\n",
        "            <span class=\"fullname\">Niels Rogge</span>\n",
        "        </div>\n",
        "    </a>\n",
        "    <a href=\"/kashif\">\n",
        "        <img class=\"avatar avatar-user\" src=\"https://avatars.githubusercontent.com/u/8100?v=4\" width=\"100\" title=\"Gravatar\">\n",
        "        <div class=\"bfc\">\n",
        "            <code>kashif</code>\n",
        "            <span class=\"fullname\">Kashif Rasul</span>\n",
        "        </div>\n",
        "    </a>\n",
        "    \n",
        "</div>\n",
        "\n",
        "<script async defer src=\"https://unpkg.com/medium-zoom-element@0/dist/medium-zoom-element.min.js\"></script>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "290edb0b",
      "metadata": {
        "id": "290edb0b"
      },
      "source": [
        "In this blog post, we'll take a deeper look into **Denoising Diffusion Probabilistic Models** (also known as DDPMs, diffusion models, score-based generative models or simply [autoencoders](https://benanne.github.io/2022/01/31/diffusion.html)) as researchers have been able to achieve remarkable results with them for (un)conditional image/audio/video generation. Popular examples (at the time of writing) include [GLIDE](https://arxiv.org/abs/2112.10741) and [DALL-E 2](https://openai.com/dall-e-2/) by OpenAI, [Latent Diffusion](https://github.com/CompVis/latent-diffusion) by the University of Heidelberg and [ImageGen](https://imagen.research.google/) by Google Brain.\n",
        "\n",
        "We'll go over the original DDPM paper by ([Ho et al., 2020](https://arxiv.org/abs/2006.11239)), implementing it step-by-step in PyTorch, based on Phil Wang's [implementation](https://github.com/lucidrains/denoising-diffusion-pytorch) - which itself is based on the [original TensorFlow implementation](https://github.com/hojonathanho/diffusion). Note that the idea of diffusion for generative modeling was actually already introduced in ([Sohl-Dickstein et al., 2015](https://arxiv.org/abs/1503.03585)). However, it took until ([Song et al., 2019](https://arxiv.org/abs/1907.05600)) (at Stanford University), and then ([Ho et al., 2020](https://arxiv.org/abs/2006.11239)) (at Google Brain) who independently improved the approach.\n",
        "\n",
        "Note that there are [several perspectives](https://twitter.com/sedielem/status/1530894256168222722?s=20&t=mfv4afx1GcNQU5fZklpACw) on diffusion models. Here, we employ the discrete-time (latent variable model) perspective, but be sure to check out the other perspectives as well."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yVijwSUfKhfY",
      "metadata": {
        "id": "yVijwSUfKhfY"
      },
      "source": [
        "Alright, let's dive in!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "M7G7djASKdWg",
      "metadata": {
        "id": "M7G7djASKdWg"
      },
      "source": [
        "<p align=\"center\">\n",
        "<img src='https://drive.google.com/uc?id=11C3cBUfz7_vrkj_4CWCyePaQyr-0m85_' width=500>\n",
        "</p>\n",
        "\n",
        "We'll install and import the required libraries first (assuming you have [PyTorch](https://pytorch.org/) installed)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a1f2d714",
      "metadata": {
        "id": "a1f2d714",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f94686b8-bdde-438e-8d69-d95749f3aa1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q -U einops datasets matplotlib tqdm\n",
        "\n",
        "import math\n",
        "from inspect import isfunction\n",
        "from functools import partial\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "from einops import rearrange\n",
        "\n",
        "import torch\n",
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fe49a34",
      "metadata": {
        "id": "6fe49a34"
      },
      "source": [
        "\n",
        "## What is a diffusion model?\n",
        "\n",
        "A (denoising) diffusion model isn't that complex if you compare it to other generative models such as Normalizing Flows, GANs or VAEs: they all convert noise from some simple distribution to a data sample. This is also the case here where **a neural network learns to gradually denoise data** starting from pure noise.\n",
        "\n",
        "In a bit more detail for images, the set-up consists of 2 processes:\n",
        "* a fixed (or predefined) forward diffusion process $q$ of our choosing, that gradually adds Gaussian noise to an image, until you end up with pure noise\n",
        "* a learned reverse denoising diffusion process $p_\\theta$, where a neural network is trained to gradually denoise an image starting from pure noise, until you end up with an actual image.\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://drive.google.com/uc?id=1t5dUyJwgy2ZpDAqHXw7GhUAp2FE5BWHA\" width=\"600\" />\n",
        "</p>\n",
        "\n",
        "Both the forward and reverse process indexed by \\\\(t\\\\) happen for some number of finite time steps \\\\(T\\\\) (the DDPM authors use \\\\(T=1000\\\\)). You start with \\\\(t=0\\\\) where you sample a real image \\\\(\\mathbf{x}_0\\\\) from your data distribution (let's say an image of a cat from ImageNet), and the forward process samples some noise from a Gaussian distribution at each time step \\\\(t\\\\), which is added to the image of the previous time step. Given a sufficiently large \\\\(T\\\\) and a well behaved schedule for adding noise at each time step, you end up with what is called an [isotropic Gaussian distribution](https://math.stackexchange.com/questions/1991961/gaussian-distribution-is-isotropic) at \\\\(t=T\\\\) via a gradual process.\n",
        "\n",
        "## In more mathematical form\n",
        "\n",
        "Let's write this down more formally, as ultimately we need a tractable loss function which our neural network needs to optimize.\n",
        "\n",
        "Let \\\\(q(\\mathbf{x}_0)\\\\) be the real data distribution, say of \"real images\". We can sample from this distribution to get an image, \\\\(\\mathbf{x}_0 \\sim q(\\mathbf{x}_0)\\\\). We define the forward diffusion process \\\\(q(\\mathbf{x}_t | \\mathbf{x}_{t-1})\\\\) which adds Gaussian noise at each time step \\\\(t\\\\), according to a known variance schedule \\\\(0 < \\beta_1 < \\beta_2 < ... < \\beta_T < 1\\\\) as\n",
        "$$\n",
        "q(\\mathbf{x}_t | \\mathbf{x}_{t-1}) = \\mathcal{N}(\\mathbf{x}_t; \\sqrt{1 - \\beta_t} \\mathbf{x}_{t-1}, \\beta_t \\mathbf{I}).\n",
        "$$\n",
        "\n",
        "Recall that a normal distribution (also called Gaussian distribution) is defined by 2 parameters: a mean \\\\(\\mu\\\\) and a variance \\\\(\\sigma^2 \\geq 0\\\\). Basically, each new (slightly noiser) image at time step \\\\(t\\\\) is drawn from a **conditional Gaussian distribution** with \\\\(\\mathbf{\\mu}_t = \\sqrt{1 - \\beta_t} \\mathbf{x}_{t-1}\\\\) and \\\\(\\sigma^2_t = \\beta_t\\\\), which we can do by sampling \\\\(\\mathbf{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\\\) and then setting \\\\(\\mathbf{x}_t = \\sqrt{1 - \\beta_t} \\mathbf{x}_{t-1} +  \\sqrt{\\beta_t} \\mathbf{\\epsilon}\\\\).\n",
        "\n",
        "Note that the \\\\(\\beta_t\\\\) aren't constant at each time step \\\\(t\\\\) (hence the subscript) --- in fact one defines a so-called **\"variance schedule\"**, which can be linear, quadratic, cosine, etc. as we will see further (a bit like a learning rate schedule).\n",
        "\n",
        "So starting from \\\\(\\mathbf{x}_0\\\\), we end up with \\\\(\\mathbf{x}_1,  ..., \\mathbf{x}_t, ..., \\mathbf{x}_T\\\\), where \\\\(\\mathbf{x}_T\\\\) is pure Gaussian noise if we set the schedule appropriately.\n",
        "\n",
        "Now, if we knew the conditional distribution \\\\(p(\\mathbf{x}_{t-1} | \\mathbf{x}_t)\\\\), then we could run the process in reverse: by sampling some random Gaussian noise \\\\(\\mathbf{x}_T\\\\), and then gradually \"denoise\" it so that we end up with a sample from the real distribution \\\\(\\mathbf{x}_0\\\\).\n",
        "\n",
        "However, we don't know \\\\(p(\\mathbf{x}_{t-1} | \\mathbf{x}_t)\\\\). It's intractable since it requires knowing the distribution of all possible images in order to calculate this conditional probability. Hence, we're going to leverage a neural network to **approximate (learn) this conditional probability distribution**, let's call it \\\\(p_\\theta (\\mathbf{x}_{t-1} | \\mathbf{x}_t)\\\\), with \\\\(\\theta\\\\) being the parameters of the neural network, updated by gradient descent.\n",
        "\n",
        "Ok, so we need a neural network to represent a (conditional) probability distribution of the backward process. If we assume this reverse process is Gaussian as well, then recall that any Gaussian distribution is defined by 2 parameters:\n",
        "* a mean parametrized by \\\\(\\mu_\\theta\\\\);\n",
        "* a variance parametrized by \\\\(\\Sigma_\\theta\\\\);\n",
        "\n",
        "so we can parametrize the process as\n",
        "$$ p_\\theta (\\mathbf{x}_{t-1} | \\mathbf{x}_t) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\mu_\\theta(\\mathbf{x}_{t},t), \\Sigma_\\theta (\\mathbf{x}_{t},t))$$\n",
        "where the mean and variance are also conditioned on the noise level \\\\(t\\\\)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d747688",
      "metadata": {
        "id": "2d747688"
      },
      "source": [
        "Hence, our neural network needs to learn/represent the mean and variance. However, the DDPM authors decided to **keep the variance fixed, and let the neural network only learn (represent) the mean \\\\(\\mu_\\theta\\\\) of this conditional probability distribution**. From the paper:\n",
        "\n",
        "> First, we set \\\\(\\Sigma_\\theta ( \\mathbf{x}_t, t) = \\sigma^2_t \\mathbf{I}\\\\) to untrained time dependent constants. Experimentally, both \\\\(\\sigma^2_t = \\beta_t\\\\) and \\\\(\\sigma^2_t  = \\tilde{\\beta}_t\\\\) (see paper) had similar results.\n",
        "\n",
        "This was then later improved in the [Improved diffusion models](https://openreview.net/pdf?id=-NEXDKk8gZ) paper, where a neural network also learns the variance of this backwards process, besides the mean.\n",
        "\n",
        "So we continue, assuming that our neural network only needs to learn/represent the mean of this conditional probability distribution.\n",
        "\n",
        "## Defining an objective function (by reparametrizing the mean)\n",
        "\n",
        "To derive an objective function to learn the mean of the backward process, the authors observe that the combination of \\\\(q\\\\) and \\\\(p_\\theta\\\\) can be seen as a variational auto-encoder (VAE) [(Kingma et al., 2013)](https://arxiv.org/abs/1312.6114). Hence, the **variational lower bound** (also called ELBO) can be used to minimize the negative log-likelihood with respect to ground truth data sample \\\\(\\mathbf{x}_0\\\\) (we refer to the VAE paper for details regarding ELBO). It turns out that the ELBO for this process is a sum of losses at each time step \\\\(t\\\\), \\\\(L = L_0 + L_1 + ... + L_T\\\\). By construction of the forward \\\\(q\\\\) process and backward process, each term (except for \\\\(L_0\\\\)) of the loss is actually the **KL divergence between 2 Gaussian distributions** which can be written explicitly as an L2-loss with respect to the means!\n",
        "\n",
        "A direct consequence of the constructed forward process \\\\(q\\\\), as shown by Sohl-Dickstein et al., is that we can sample \\\\(\\mathbf{x}_t\\\\) at any arbitrary noise level conditioned on \\\\(\\mathbf{x}_0\\\\) (since sums of Gaussians is also Gaussian). This is very convenient:  we don't need to apply \\\\(q\\\\) repeatedly in order to sample \\\\(\\mathbf{x}_t\\\\).\n",
        "We have that\n",
        "$$q(\\mathbf{x}_t | \\mathbf{x}_0) = \\cal{N}(\\mathbf{x}_t; \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0, (1- \\bar{\\alpha}_t) \\mathbf{I})$$\n",
        "\n",
        "with \\\\(\\alpha_t := 1 - \\beta_t\\\\) and \\\\(\\bar{\\alpha}t := \\Pi_{s=1}^{t} \\alpha_s\\\\). Let's refer to this equation as the \"nice property\". This means we can sample Gaussian noise and scale it appropriatly and add it to \\\\(\\mathbf{x}_0\\\\) to get \\\\(\\mathbf{x}_t\\\\) directly. Note that the \\\\(\\bar{\\alpha}_t\\\\) are functions of the known \\\\(\\beta_t\\\\) variance schedule and thus are also known and can be precomputed. This then allows us, during training, to **optimize random terms of the loss function \\\\(L\\\\)** (or in other words, to randomly sample \\\\(t\\\\) during training and optimize \\\\(L_t\\\\)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68574c28",
      "metadata": {
        "id": "68574c28"
      },
      "source": [
        "Another beauty of this property, as shown in Ho et al. is that one can (after some math, for which we refer the reader to [this excellent blog post](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)) instead **reparametrize the mean to make the neural network learn (predict) the added noise (via a network \\\\(\\mathbf{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\\\) for noise level \\\\(t\\\\)** in the KL terms which constitute the losses. This means that our neural network becomes a noise predictor, rather than a (direct) mean predictor. The mean can be computed as follows:\n",
        "\n",
        "$$ \\mathbf{\\mu}_\\theta(\\mathbf{x}_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left(  \\mathbf{x}_t - \\frac{\\beta_t}{\\sqrt{1- \\bar{\\alpha}_t}} \\mathbf{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\right)$$\n",
        "\n",
        "The final objective function \\\\(L_t\\\\) then looks as follows (for a random time step \\\\(t\\\\) given \\\\(\\mathbf{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{I})\\\\) ):\n",
        "\n",
        "$$ \\| \\mathbf{\\epsilon} - \\mathbf{\\epsilon}_\\theta(\\mathbf{x}_t, t) \\|^2 = \\| \\mathbf{\\epsilon} - \\mathbf{\\epsilon}_\\theta( \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{(1- \\bar{\\alpha}_t)  } \\mathbf{\\epsilon}, t) \\|^2.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5153024b",
      "metadata": {
        "id": "5153024b"
      },
      "source": [
        "Here, \\\\(\\mathbf{x}_0\\\\) is the initial (real, uncorruped) image, and we see the direct noise level \\\\(t\\\\) sample given by the fixed forward process. \\\\(\\mathbf{\\epsilon}\\\\) is the pure noise sampled at time step \\\\(t\\\\), and \\\\(\\mathbf{\\epsilon}_\\theta (\\mathbf{x}_t, t)\\\\) is our neural network. The neural network is optimized using a simple mean squared error (MSE) between the true and the predicted Gaussian noise.\n",
        "\n",
        "The training algorithm now looks as follows:\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://drive.google.com/uc?id=1LJsdkZ3i1J32lmi9ONMqKFg5LMtpSfT4\" width=\"400\" />\n",
        "</p>\n",
        "\n",
        "In other words:\n",
        "* we take a random sample $\\mathbf{x}_0$ from the real unknown and possibily complex data distribution $q(\\mathbf{x}_0)$\n",
        "* we sample a noise level $t$ uniformally between $1$ and $T$ (i.e., a random time step)\n",
        "* we sample some noise from a Gaussian distribution and corrupt the input by this noise at level $t$ using the nice property defined above\n",
        "* the neural network is trained to predict this noise based on the corruped image $\\mathbf{x}_t$, i.e. noise applied on $\\mathbf{x}_0$ based on known schedule $\\beta_t$\n",
        "\n",
        "In reality, all of this is done on batches of data as one uses stochastic gradient descent to optimize neural networks.\n",
        "\n",
        "## The neural network\n",
        "\n",
        "The neural network needs to take in a noised image at a particular time step and return the predicted noise. Note that the predicted noise is a tensor that has the same size/resolution as the input image. So technically, the network takes in and outputs tensors of the same shape. What type of neural network can we use for this?\n",
        "\n",
        "What is typically used here is very similar to that of an [Autoencoder](https://en.wikipedia.org/wiki/Autoencoder), which you may remember from typical \"intro to deep learning\" tutorials. Autoencoders have a so-called \"bottleneck\" layer in between the encoder and decoder. The encoder first encodes an image into a smaller hidden representation called the \"bottleneck\", and the decoder then decodes that hidden representation back into an actual image. This forces the network to only keep the most important information in the bottleneck layer.\n",
        "\n",
        "In terms of architecture, the DDPM authors went for a **U-Net**, introduced by ([Ronneberger et al., 2015](https://arxiv.org/abs/1505.04597)) (which, at the time, achieved state-of-the-art results for medical image segmentation). This network, like any autoencoder, consists of a bottleneck in the middle that makes sure the network learns only the most important information. Importantly, it introduced residual connections between the encoder and decoder, greatly improving gradient flow (inspired by ResNet in [He et al., 2015](https://arxiv.org/abs/1512.03385)).\n",
        "\n",
        "<p align=\"center\">\n",
        "    <img src=\"https://drive.google.com/uc?id=1_Hej_VTgdUWGsxxIuyZACCGjpbCGIUi6\" width=\"400\" />\n",
        "</p>\n",
        "\n",
        "As can be seen, a U-Net model first downsamples the input (i.e. makes the input smaller in terms of spatial resolution), after which upsampling is performed.\n",
        "\n",
        "Below, we implement this network, step-by-step.\n",
        "\n",
        "### Network helpers\n",
        "\n",
        "First, we define some helper functions and classes which will be used when implementing the neural network. Importantly, we define a `Residual` module, which simply adds the input to the output of a particular function (in other words, adds a residual connection to a particular function).\n",
        "\n",
        "We also define aliases for the up- and downsampling operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "68907f5d",
      "metadata": {
        "id": "68907f5d"
      },
      "outputs": [],
      "source": [
        "def exists(x):\n",
        "    return x is not None\n",
        "\n",
        "def default(val, d):\n",
        "    if exists(val):\n",
        "        return val\n",
        "    return d() if isfunction(d) else d\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        return self.fn(x, *args, **kwargs) + x\n",
        "\n",
        "def Upsample(dim):\n",
        "    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)\n",
        "\n",
        "def Downsample(dim):\n",
        "    return nn.Conv2d(dim, dim, 4, 2, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "592aa765",
      "metadata": {
        "id": "592aa765"
      },
      "source": [
        "### Position embeddings\n",
        "\n",
        "As the parameters of the neural network are shared across time (noise level), the authors employ sinusoidal position embeddings to encode $t$, inspired by the Transformer ([Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)). This makes the neural network \"know\" at which particular time step (noise level) it is operating, for every image in a batch.\n",
        "\n",
        "The `SinusoidalPositionEmbeddings` module takes a tensor of shape `(batch_size, 1)` as input (i.e. the noise levels of several noisy images in a batch), and turns this into a tensor of shape `(batch_size, dim)`, with `dim` being the dimensionality of the position embeddings. This is then added to each residual block, as we will see further."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5ed0757b",
      "metadata": {
        "id": "5ed0757b"
      },
      "outputs": [],
      "source": [
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = math.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        return embeddings\n",
        "\n",
        "#ITT"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ff47fbb",
      "metadata": {
        "id": "9ff47fbb"
      },
      "source": [
        "### ResNet/ConvNeXT block\n",
        "\n",
        "Next, we define the core building block of the U-Net model. The DDPM authors employed a Wide ResNet block ([Zagoruyko et al., 2016](https://arxiv.org/abs/1605.07146)), but Phil Wang decided to also add support for a ConvNeXT block ([Liu et al., 2022](https://arxiv.org/abs/2201.03545)), as the latter has achieved great success in the image domain. One can choose one or another in the final U-Net architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2c2d1219",
      "metadata": {
        "id": "2c2d1219"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, dim, dim_out, groups = 8):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Conv2d(dim, dim_out, 3, padding = 1)\n",
        "        self.norm = nn.GroupNorm(groups, dim_out)\n",
        "        self.act = nn.SiLU()\n",
        "\n",
        "    def forward(self, x, scale_shift = None):\n",
        "        x = self.proj(x)\n",
        "        x = self.norm(x)\n",
        "\n",
        "        if exists(scale_shift):\n",
        "            scale, shift = scale_shift\n",
        "            x = x * (scale + 1) + shift\n",
        "\n",
        "        x = self.act(x)\n",
        "        return x\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "    \"\"\"https://arxiv.org/abs/1512.03385\"\"\"\n",
        "\n",
        "    def __init__(self, dim, dim_out, *, time_emb_dim=None, groups=8):\n",
        "        super().__init__()\n",
        "        self.mlp = (\n",
        "            nn.Sequential(nn.SiLU(), nn.Linear(time_emb_dim, dim_out))\n",
        "            if exists(time_emb_dim)\n",
        "            else None\n",
        "        )\n",
        "\n",
        "        self.block1 = Block(dim, dim_out, groups=groups)\n",
        "        self.block2 = Block(dim_out, dim_out, groups=groups)\n",
        "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x, time_emb=None):\n",
        "        h = self.block1(x)\n",
        "\n",
        "        if exists(self.mlp) and exists(time_emb):\n",
        "            time_emb = self.mlp(time_emb)\n",
        "            h = rearrange(time_emb, \"b c -> b c 1 1\") + h\n",
        "\n",
        "        h = self.block2(h)\n",
        "        return h + self.res_conv(x)\n",
        "\n",
        "class ConvNextBlock(nn.Module):\n",
        "    \"\"\"https://arxiv.org/abs/2201.03545\"\"\"\n",
        "\n",
        "    def __init__(self, dim, dim_out, *, time_emb_dim=None, mult=2, norm=True):\n",
        "        super().__init__()\n",
        "        self.mlp = (\n",
        "            nn.Sequential(nn.GELU(), nn.Linear(time_emb_dim, dim))\n",
        "            if exists(time_emb_dim)\n",
        "            else None\n",
        "        )\n",
        "\n",
        "        self.ds_conv = nn.Conv2d(dim, dim, 7, padding=3, groups=dim)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.GroupNorm(1, dim) if norm else nn.Identity(),\n",
        "            nn.Conv2d(dim, dim_out * mult, 3, padding=1),\n",
        "            nn.GELU(),\n",
        "            nn.GroupNorm(1, dim_out * mult),\n",
        "            nn.Conv2d(dim_out * mult, dim_out, 3, padding=1),\n",
        "        )\n",
        "\n",
        "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x, time_emb=None):\n",
        "        h = self.ds_conv(x)\n",
        "\n",
        "        if exists(self.mlp) and exists(time_emb):\n",
        "            assert exists(time_emb), \"time embedding must be passed in\"\n",
        "            condition = self.mlp(time_emb)\n",
        "            h = h + rearrange(condition, \"b c -> b c 1 1\")\n",
        "\n",
        "        h = self.net(h)\n",
        "        return h + self.res_conv(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51d9a24c",
      "metadata": {
        "id": "51d9a24c"
      },
      "source": [
        "### Attention module\n",
        "\n",
        "Next, we define the attention module, which the DDPM authors added in between the convolutional blocks. Attention is the building block of the famous Transformer architecture ([Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)), which has shown great success in various domains of AI, from NLP and vision to [protein folding](https://www.deepmind.com/blog/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology). Phil Wang employs 2 variants of attention: one is regular multi-head self-attention (as used in the Transformer), the other one is a [linear attention variant](https://github.com/lucidrains/linear-attention-transformer) ([Shen et al., 2018](https://arxiv.org/abs/1812.01243)), whose time- and memory requirements scale linear in the sequence length, as opposed to quadratic for regular attention.\n",
        "\n",
        "For an extensive explanation of the attention mechanism, we refer the reader to Jay Allamar's [wonderful blog post](https://jalammar.github.io/illustrated-transformer/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "07bbd544",
      "metadata": {
        "id": "07bbd544"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads=4, dim_head=32):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head**-0.5\n",
        "        self.heads = heads\n",
        "        hidden_dim = dim_head * heads\n",
        "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
        "        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
        "        q, k, v = map(\n",
        "            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n",
        "        )\n",
        "        q = q * self.scale\n",
        "\n",
        "        sim = einsum(\"b h d i, b h d j -> b h i j\", q, k)\n",
        "        sim = sim - sim.amax(dim=-1, keepdim=True).detach()\n",
        "        attn = sim.softmax(dim=-1)\n",
        "\n",
        "        out = einsum(\"b h i j, b h d j -> b h i d\", attn, v)\n",
        "        out = rearrange(out, \"b h (x y) d -> b (h d) x y\", x=h, y=w)\n",
        "        return self.to_out(out)\n",
        "\n",
        "class LinearAttention(nn.Module):\n",
        "    def __init__(self, dim, heads=4, dim_head=32):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head**-0.5\n",
        "        self.heads = heads\n",
        "        hidden_dim = dim_head * heads\n",
        "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias=False)\n",
        "\n",
        "        self.to_out = nn.Sequential(nn.Conv2d(hidden_dim, dim, 1),\n",
        "                                    nn.GroupNorm(1, dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
        "        q, k, v = map(\n",
        "            lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv\n",
        "        )\n",
        "\n",
        "        q = q.softmax(dim=-2)\n",
        "        k = k.softmax(dim=-1)\n",
        "\n",
        "        q = q * self.scale\n",
        "        context = torch.einsum(\"b h d n, b h e n -> b h d e\", k, v)\n",
        "\n",
        "        out = torch.einsum(\"b h d e, b h d n -> b h e n\", context, q)\n",
        "        out = rearrange(out, \"b h c (x y) -> b (h c) x y\", h=self.heads, x=h, y=w)\n",
        "        return self.to_out(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a8031b0",
      "metadata": {
        "id": "9a8031b0"
      },
      "source": [
        "### Group normalization\n",
        "\n",
        "The DDPM authors interleave the convolutional/attention layers of the U-Net with group normalization ([Wu et al., 2018](https://arxiv.org/abs/1803.08494)). Below, we define a `PreNorm` class, which will be used to apply groupnorm before the attention layer, as we'll see further. Note that there's been a [debate](https://tnq177.github.io/data/transformers_without_tears.pdf) about whether to apply normalization before or after attention in Transformers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5e2ce68f",
      "metadata": {
        "id": "5e2ce68f"
      },
      "outputs": [],
      "source": [
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "        self.norm = nn.GroupNorm(1, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm(x)\n",
        "        return self.fn(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06b3fad0",
      "metadata": {
        "id": "06b3fad0"
      },
      "source": [
        "### Conditional U-Net\n",
        "\n",
        "Now that we've defined all building blocks (position embeddings, ResNet/ConvNeXT blocks, attention and group normalization), it's time to define the entire neural network. Recall that the job of the network \\\\(\\mathbf{\\epsilon}_\\theta(\\mathbf{x}_t, t)\\\\) is to take in a batch of noisy images + noise levels, and output the noise added to the input. More formally:\n",
        "\n",
        "- the network takes a batch of noisy images of shape `(batch_size, num_channels, height, width)` and a batch of noise levels of shape `(batch_size, 1)` as input, and returns a tensor of shape `(batch_size, num_channels, height, width)`\n",
        "\n",
        "The network is built up as follows:\n",
        "* first, a convolutional layer is applied on the batch of noisy images, and position embeddings are computed for the noise levels\n",
        "* next, a sequence of downsampling stages are applied. Each downsampling stage consists of 2 ResNet/ConvNeXT blocks + groupnorm + attention + residual connection + a downsample operation\n",
        "* at the middle of the network, again ResNet or ConvNeXT blocks are applied, interleaved with attention\n",
        "* next, a sequence of upsampling stages are applied. Each upsampling stage consists of 2 ResNet/ConvNeXT blocks + groupnorm + attention + residual connection + an upsample operation\n",
        "* finally, a ResNet/ConvNeXT block followed by a convolutional layer is applied.\n",
        "\n",
        "Ultimately, neural networks stack up layers as if they were lego blocks (but it's important to [understand how they work](http://karpathy.github.io/2019/04/25/recipe/)).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3a159023",
      "metadata": {
        "id": "3a159023"
      },
      "outputs": [],
      "source": [
        "class Unet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        init_dim=None,\n",
        "        out_dim=None,\n",
        "        dim_mults=(1, 2, 4, 8),\n",
        "        channels=3,\n",
        "        with_time_emb=True,\n",
        "        resnet_block_groups=8,\n",
        "        use_convnext=True,\n",
        "        convnext_mult=2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # determine dimensions\n",
        "        self.channels = channels\n",
        "\n",
        "        init_dim = default(init_dim, dim // 3 * 2)\n",
        "        self.init_conv = nn.Conv2d(channels, init_dim, 7, padding=3)\n",
        "\n",
        "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
        "        in_out = list(zip(dims[:-1], dims[1:]))\n",
        "\n",
        "        if use_convnext:\n",
        "            block_klass = partial(ConvNextBlock, mult=convnext_mult)\n",
        "        else:\n",
        "            block_klass = partial(ResnetBlock, groups=resnet_block_groups)\n",
        "\n",
        "        # time embeddings\n",
        "        if with_time_emb:\n",
        "            time_dim = dim * 4\n",
        "            self.time_mlp = nn.Sequential(\n",
        "                SinusoidalPositionEmbeddings(dim),\n",
        "                nn.Linear(dim, time_dim),\n",
        "                nn.GELU(),\n",
        "                nn.Linear(time_dim, time_dim),\n",
        "            )\n",
        "        else:\n",
        "            time_dim = None\n",
        "            self.time_mlp = None\n",
        "\n",
        "        # layers\n",
        "        self.downs = nn.ModuleList([])\n",
        "        self.ups = nn.ModuleList([])\n",
        "        num_resolutions = len(in_out)\n",
        "\n",
        "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
        "            is_last = ind >= (num_resolutions - 1)\n",
        "\n",
        "            self.downs.append(\n",
        "                nn.ModuleList(\n",
        "                    [\n",
        "                        block_klass(dim_in, dim_out, time_emb_dim=time_dim),\n",
        "                        block_klass(dim_out, dim_out, time_emb_dim=time_dim),\n",
        "                        Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
        "                        Downsample(dim_out) if not is_last else nn.Identity(),\n",
        "                    ]\n",
        "                )\n",
        "            )\n",
        "\n",
        "        mid_dim = dims[-1]\n",
        "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
        "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
        "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim=time_dim)\n",
        "\n",
        "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
        "            is_last = ind >= (num_resolutions - 1)\n",
        "\n",
        "            self.ups.append(\n",
        "                nn.ModuleList(\n",
        "                    [\n",
        "                        block_klass(dim_out * 2, dim_in, time_emb_dim=time_dim),\n",
        "                        block_klass(dim_in, dim_in, time_emb_dim=time_dim),\n",
        "                        Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
        "                        Upsample(dim_in) if not is_last else nn.Identity(),\n",
        "                    ]\n",
        "                )\n",
        "            )\n",
        "\n",
        "        out_dim = default(out_dim, channels)\n",
        "        self.final_conv = nn.Sequential(\n",
        "            block_klass(dim, dim), nn.Conv2d(dim, out_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, time):\n",
        "        x = self.init_conv(x)\n",
        "\n",
        "        t = self.time_mlp(time) if exists(self.time_mlp) else None\n",
        "\n",
        "        h = []\n",
        "\n",
        "        # downsample\n",
        "        for block1, block2, attn, downsample in self.downs:\n",
        "            x = block1(x, t)\n",
        "            x = block2(x, t)\n",
        "            x = attn(x)\n",
        "            h.append(x)\n",
        "            x = downsample(x)\n",
        "\n",
        "        # bottleneck\n",
        "        x = self.mid_block1(x, t)\n",
        "        x = self.mid_attn(x)\n",
        "        x = self.mid_block2(x, t)\n",
        "\n",
        "        # upsample\n",
        "        for block1, block2, attn, upsample in self.ups:\n",
        "            x = torch.cat((x, h.pop()), dim=1)\n",
        "            x = block1(x, t)\n",
        "            x = block2(x, t)\n",
        "            x = attn(x)\n",
        "            x = upsample(x)\n",
        "\n",
        "        return self.final_conv(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a30368b2",
      "metadata": {
        "id": "a30368b2"
      },
      "source": [
        "## Defining the forward diffusion process\n",
        "\n",
        "The forward diffusion process gradually adds noise to an image from the real distribution, in a number of time steps $T$. This happens according to a **variance schedule**. The original DDPM authors employed a linear schedule:\n",
        "\n",
        "> We set the forward process variances to constants\n",
        "increasing linearly from $\\beta_1 = 10^{−4}$\n",
        "to $\\beta_T = 0.02$.\n",
        "\n",
        "However, it was shown in ([Nichol et al., 2021](https://arxiv.org/abs/2102.09672)) that better results can be achieved when employing a cosine schedule.\n",
        "\n",
        "Below, we define various schedules for the $T$ timesteps, as well as corresponding variables which we'll need, such as cumulative variances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5d751df2",
      "metadata": {
        "id": "5d751df2"
      },
      "outputs": [],
      "source": [
        "def cosine_beta_schedule(timesteps, s=0.008):\n",
        "    \"\"\"\n",
        "    cosine schedule as proposed in https://arxiv.org/abs/2102.09672\n",
        "    \"\"\"\n",
        "    steps = timesteps + 1\n",
        "    x = torch.linspace(0, timesteps, steps)\n",
        "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return torch.clip(betas, 0.0001, 0.9999)\n",
        "\n",
        "def linear_beta_schedule(timesteps):\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    return torch.linspace(beta_start, beta_end, timesteps)\n",
        "\n",
        "def quadratic_beta_schedule(timesteps):\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    return torch.linspace(beta_start**0.5, beta_end**0.5, timesteps) ** 2\n",
        "\n",
        "def sigmoid_beta_schedule(timesteps):\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    betas = torch.linspace(-6, 6, timesteps)\n",
        "    return torch.sigmoid(betas) * (beta_end - beta_start) + beta_start"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bfc3841",
      "metadata": {
        "id": "6bfc3841"
      },
      "source": [
        "To start with, let's use the linear schedule for \\\\(T=200\\\\) time steps and define the various variables from the \\\\(\\beta_t\\\\) which we will need, such as the cumulative product of the variances \\\\(\\bar{\\alpha}_t\\\\). Each of the variables below are just 1-dimensional tensors, storing values from \\\\(t\\\\) to \\\\(T\\\\). Importantly, we also define an `extract` function, which will allow us to extract the appropriate \\\\(t\\\\) index for a batch of indices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cc57b01f",
      "metadata": {
        "id": "cc57b01f"
      },
      "outputs": [],
      "source": [
        "timesteps = 200\n",
        "\n",
        "# define beta schedule\n",
        "betas = linear_beta_schedule(timesteps=timesteps)\n",
        "\n",
        "# define alphas\n",
        "alphas = 1. - betas\n",
        "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
        "\n",
        "# calculations for diffusion q(x_t | x_{t-1}) and others\n",
        "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
        "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
        "\n",
        "# calculations for posterior q(x_{t-1} | x_t, x_0)\n",
        "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
        "\n",
        "def extract(a, t, x_shape):\n",
        "    batch_size = t.shape[0]\n",
        "    out = a.gather(-1, t.cpu())\n",
        "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48f8a004",
      "metadata": {
        "id": "48f8a004"
      },
      "source": [
        "We'll illustrate with a cats image how noise is added at each time step of the diffusion process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "71aba861",
      "metadata": {
        "id": "71aba861"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import Compose, ToTensor, Lambda, ToPILImage, CenterCrop, Resize\n",
        "\n",
        "image_size = 128\n",
        "transform = Compose([\n",
        "    Resize(image_size),\n",
        "    CenterCrop(image_size),\n",
        "    ToTensor(), # turn into Numpy array of shape HWC, divide by 255\n",
        "    Lambda(lambda t: (t * 2) - 1),\n",
        "\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e143cc62",
      "metadata": {
        "id": "e143cc62"
      },
      "source": [
        "<div class=\"output stream stdout\">\n",
        "\n",
        "    Output:\n",
        "    ----------------------------------------------------------------------------------------------------\n",
        "    torch.Size([1, 3, 128, 128])\n",
        "\n",
        "</div>\n",
        "\n",
        "We also define the reverse transform, which takes in a PyTorch tensor containing values in $[-1, 1]$ and turn them back into a PIL image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b98e91ff",
      "metadata": {
        "id": "b98e91ff"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "reverse_transform = Compose([\n",
        "     Lambda(lambda t: (t + 1) / 2),\n",
        "     Lambda(lambda t: t.permute(1, 2, 0)), # CHW to HWC\n",
        "     Lambda(lambda t: t * 255.),\n",
        "     Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
        "     ToPILImage(),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6869ab7",
      "metadata": {
        "id": "f6869ab7"
      },
      "source": [
        "Let's verify this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f3752480",
      "metadata": {
        "id": "f3752480"
      },
      "outputs": [],
      "source": [
        "# forward diffusion\n",
        "def q_sample(x_start, t, noise=None):\n",
        "    if noise is None:\n",
        "        noise = torch.randn_like(x_start)\n",
        "\n",
        "    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_start.shape)\n",
        "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
        "        sqrt_one_minus_alphas_cumprod, t, x_start.shape\n",
        "    )\n",
        "\n",
        "    return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e82bac28",
      "metadata": {
        "id": "e82bac28"
      },
      "source": [
        "Let's test it on a particular time step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6bd64f89",
      "metadata": {
        "id": "6bd64f89"
      },
      "outputs": [],
      "source": [
        "def get_noisy_image(x_start, t):\n",
        "  # add noise\n",
        "  x_noisy = q_sample(x_start, t=t)\n",
        "\n",
        "  # turn back into PIL image\n",
        "  noisy_image = reverse_transform(x_noisy.squeeze())\n",
        "\n",
        "  return noisy_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8e27c37d",
      "metadata": {
        "id": "8e27c37d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# use seed for reproducability\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# source: https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
        "def plot(imgs, with_orig=False, row_title=None, **imshow_kwargs):\n",
        "    if not isinstance(imgs[0], list):\n",
        "        # Make a 2d grid even if there's just 1 row\n",
        "        imgs = [imgs]\n",
        "\n",
        "    num_rows = len(imgs)\n",
        "    num_cols = len(imgs[0]) + with_orig\n",
        "    fig, axs = plt.subplots(figsize=(200,200), nrows=num_rows, ncols=num_cols, squeeze=False)\n",
        "    for row_idx, row in enumerate(imgs):\n",
        "        row = [image] + row if with_orig else row\n",
        "        for col_idx, img in enumerate(row):\n",
        "            ax = axs[row_idx, col_idx]\n",
        "            ax.imshow(np.asarray(img), **imshow_kwargs)\n",
        "            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "\n",
        "    if with_orig:\n",
        "        axs[0, 0].set(title='Original image')\n",
        "        axs[0, 0].title.set_size(8)\n",
        "    if row_title is not None:\n",
        "        for row_idx in range(num_rows):\n",
        "            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n",
        "\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7725f6cf",
      "metadata": {
        "id": "7725f6cf"
      },
      "outputs": [],
      "source": [
        "def p_losses(denoise_model, x_start, t, noise=None, loss_type=\"l1\"):\n",
        "    if noise is None:\n",
        "        noise = torch.randn_like(x_start)\n",
        "\n",
        "    x_noisy = q_sample(x_start=x_start, t=t, noise=noise)\n",
        "    predicted_noise = denoise_model(x_noisy, t)\n",
        "\n",
        "    if loss_type == 'l1':\n",
        "        loss = F.l1_loss(noise, predicted_noise)\n",
        "    elif loss_type == 'l2':\n",
        "        loss = F.mse_loss(noise, predicted_noise)\n",
        "    elif loss_type == \"huber\":\n",
        "        loss = F.smooth_l1_loss(noise, predicted_noise)\n",
        "    else:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc01c63b",
      "metadata": {
        "id": "cc01c63b"
      },
      "source": [
        "The `denoise_model` will be our U-Net defined above. We'll employ the Huber loss between the true and the predicted noise.\n",
        "\n",
        "## Define a PyTorch Dataset + DataLoader\n",
        "\n",
        "Here we define a regular [PyTorch Dataset](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html). The dataset simply consists of images from a real dataset, like Fashion-MNIST, CIFAR-10 or ImageNet, scaled linearly to \\\\([−1, 1]\\\\).\n",
        "\n",
        "Each image is resized to the same size. Interesting to note is that images are also randomly horizontally flipped. From the paper:\n",
        "\n",
        "> We used random horizontal flips during training for CIFAR10; we tried training both with and without flips, and found flips to improve sample quality slightly.\n",
        "\n",
        "Here we use the 🤗 [Datasets library](https://huggingface.co/docs/datasets/index) to easily load the Fashion MNIST dataset from the [hub](https://huggingface.co/datasets/fashion_mnist). This dataset consists of images which already have the same resolution, namely 28x28."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9_dpvwhTqxuz"
      },
      "id": "9_dpvwhTqxuz",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torchvision.datasets.Flowers102(root='./datasetflowers', download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utbCuti1qzNC",
        "outputId": "c078d07e-9a43-4eac-ea64-52aa9487f499"
      },
      "id": "utbCuti1qzNC",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to datasetflowers/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 344862509/344862509 [00:01<00:00, 194971280.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting datasetflowers/flowers-102/102flowers.tgz to datasetflowers/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to datasetflowers/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 1317609.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to datasetflowers/flowers-102/setid.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 45789091.52it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6134d691",
      "metadata": {
        "id": "6134d691",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "01423017e024419ebbb80e4c43cf0216",
            "fa27118af23a41bcadd3c6796eb5ecf7",
            "cff8b07a6fa14c0aa87fa3fb5afe2ac9",
            "2130d822372f4f6abb03291e92fa546f",
            "ed4d02e7561f40ba973a264c219e1657",
            "3b3ef2a6609c46fbb958712fd82cdabc",
            "df1f1599429c4c96a97b03e2ff14742b",
            "a0e2655a62e3453dad032f81423eea73",
            "098352c2ee3245d790434d5c5f482421",
            "c0ee8fbec972496f9fdd1fc95861fe80",
            "77af21838d95434db3d7eb2fad44b69d",
            "c4f5ff81658f43139a88f7616c438c61",
            "1d9c076fb8d047daafa521757335d2d7",
            "0dd051afc771499383d366ac29ff976d",
            "44b1cc5bfd254c8794f52883f8fdc279",
            "3b048c588f3d4100bf2d0d0c90335075",
            "94f31f793fa24bd19301b8a3c321309d",
            "8e262e626e434fa395f9e3099c3a1712",
            "40690a7058eb457182d545be7cb9b4e0",
            "0d5a4ca2352e4fe281a5e85d7e9ae4ff",
            "063d5d8b3fc0422f908700f0c0ccd186",
            "6389c17ce7474602963842db2d6cce64",
            "8b438025e252405494bc05e25e4cf28d",
            "6d6f3798d16c4c4c9d4f4aa2374ccd16",
            "371827e54f7c4289a26ffb2c471d5598",
            "9b66ba475a3248cf81fe85a4ae44abc7",
            "10294d6e329948d5864a28f8a846bd8f",
            "e2c2b425886e40138880dc2d0bc2f610",
            "3c31c17cb2c545f0b311c3f498c11472",
            "80223ccb8f6543819fe25559339bf363",
            "279b0b0c4ab1424d8ea24cb95aa1878a",
            "21811134f0114bd0aa9e112c1cbad590",
            "6d223f5cf4034a338e3dd0d07f70e236",
            "5db064820ab7471b828396e7a024ca5c",
            "c4517b28ccd44809983b3456c8308001",
            "8a4b2ccaef7b4512b8f46fb996a00216",
            "c29c34a2f27947089c4769375aed7598",
            "52cab01533d24ff684529a3eb23e19f7",
            "9fbca02247b44e2285f8d7e60d7727e6",
            "188ff26dad9041e7b778ca90188f3970",
            "37520fc4802d40a78fc6860f215161d6",
            "aef9c58ae4a54f84b23ac00107e42a0a",
            "12f1e7f4456f4decbcbcb23f8cb110aa",
            "f3654cd797984731b2cb1d4b3a06b2e1",
            "3ebf87c9aa92432b9b76e0c27d70850e",
            "341f6cd5272e40b884212c561068806a",
            "83beead9fd504de7a2334acf37bfb2b5",
            "ce0ba74d4cb94a5285bb36fd783396cc",
            "9e290f6900d1402ab0b5e08fa2cb7666",
            "1514aa78ae0746569ab95efb1fe7f464",
            "b566c65dfb0849d98e294f65c0685c9a",
            "511bef34fce647fcb50a5d9aa9283f40",
            "9f0cb0bf4cfb4f4f9ed01a3cfa208ea0",
            "00251177652c485c9da8f809c699a881",
            "af6448f18db2453f9556ae682b0d85f9"
          ]
        },
        "outputId": "b654781c-5ffa-41b2-f6b8-b0066ba60c6f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/8189 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01423017e024419ebbb80e4c43cf0216"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/8189 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4f5ff81658f43139a88f7616c438c61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b438025e252405494bc05e25e4cf28d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5db064820ab7471b828396e7a024ca5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ebf87c9aa92432b9b76e0c27d70850e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"datasetflowers\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 64\n",
        "channels = 3\n",
        "batch_size = 32\n"
      ],
      "metadata": {
        "id": "mRDYoBZWq_wB"
      },
      "id": "mRDYoBZWq_wB",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z7Or0u6rKhu",
        "outputId": "a2f626fc-4875-4fae-9b90-8eb81f168a86"
      },
      "id": "4z7Or0u6rKhu",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['image'],\n",
              "        num_rows: 8189\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Get the first image from the dataset\n",
        "# first_image = dataset['train'][0]['image']\n",
        "\n",
        "# # Convert the PIL Image to a numpy array\n",
        "# first_image = np.array(first_image)\n",
        "\n",
        "# # Display the image\n",
        "# plt.imshow(first_image)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "OUTdl3WdrPyt"
      },
      "id": "OUTdl3WdrPyt",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tVJglkqFrVh7"
      },
      "id": "tVJglkqFrVh7",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "db6f5875",
      "metadata": {
        "id": "db6f5875"
      },
      "source": [
        "Next, we define a function which we'll apply on-the-fly on the entire dataset. We use the `with_transform` [functionality](https://huggingface.co/docs/datasets/v2.2.1/en/package_reference/main_classes#datasets.Dataset.with_transform) for that. The function just applies some basic image preprocessing: random horizontal flips, rescaling and finally make them have values in the $[-1,1]$ range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b3e78945",
      "metadata": {
        "id": "b3e78945"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import Compose, ToTensor, Lambda, ToPILImage, CenterCrop, Resize\n",
        "\n",
        "# define image transformations (e.g. using torchvision)\n",
        "transform = Compose([\n",
        "            transforms.Resize(64),\n",
        "            transforms.CenterCrop(64),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
        "])\n",
        "\n",
        "# define function\n",
        "def transforms(examples):\n",
        "   examples[\"pixel_values\"] = [transform(image) for image in examples[\"image\"]]\n",
        "   del examples[\"image\"]\n",
        "\n",
        "   return examples\n",
        "\n",
        "transformed_dataset = dataset.with_transform(transforms)\n",
        "\n",
        "# create dataloader\n",
        "dataloader = DataLoader(transformed_dataset[\"train\"], batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Get one batch of images\n",
        "# images = next(iter(dataloader))[\"pixel_values\"]\n",
        "\n",
        "# # Reverse the transformation to get the pixel values back to the range [0, 1]\n",
        "# reversed_images = (images + 1) / 2\n",
        "\n",
        "# # Now you can visualize the images\n",
        "# first_image = reversed_images[0]\n",
        "\n",
        "# # If the images are grayscale, we need to remove the channel dimension\n",
        "# if first_image.dim() == 2:\n",
        "#     plt.imshow(first_image)\n",
        "# else:\n",
        "#     plt.imshow(first_image.permute(1, 2, 0))\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "ZYXyN5pjrrtI"
      },
      "id": "ZYXyN5pjrrtI",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "52e8273b",
      "metadata": {
        "id": "52e8273b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a35a9d6-37ec-4c99-ca3c-90fe9463f5c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['pixel_values'])\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(dataloader))\n",
        "print(batch.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4325faf",
      "metadata": {
        "id": "e4325faf"
      },
      "source": [
        "<div class=\"output stream stdout\">\n",
        "\n",
        "    Output:\n",
        "    ----------------------------------------------------------------------------------------------------\n",
        "    dict_keys(['pixel_values'])\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cf98443",
      "metadata": {
        "id": "4cf98443"
      },
      "source": [
        "## Sampling\n",
        "\n",
        "As we'll sample from the model during training (in order to track progress), we define the code for that below. Sampling is summarized in the paper as Algorithm 2:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1ij80f8TNBDzpKtqHjk_sh8o5aby3lmD7\" width=\"500\" />\n",
        "\n",
        "Generating new images from a diffusion model happens by reversing the diffusion process: we start from $T$, where we sample pure noise from a Gaussian distribution, and then use our neural network to gradually denoise it (using the conditional probability it has learned), until we end up at time step $t = 0$. As shown above, we can derive a slighly less denoised image $\\mathbf{x}_{t-1 }$ by plugging in the reparametrization of the mean, using our noise predictor. Remember that the variance is known ahead of time.\n",
        "\n",
        "Ideally, we end up with an image that looks like it came from the real data distribution.\n",
        "\n",
        "The code below implements this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f7628fb3",
      "metadata": {
        "id": "f7628fb3"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def p_sample(model, x, t, t_index):\n",
        "    betas_t = extract(betas, t, x.shape)\n",
        "    sqrt_one_minus_alphas_cumprod_t = extract(\n",
        "        sqrt_one_minus_alphas_cumprod, t, x.shape\n",
        "    )\n",
        "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)\n",
        "\n",
        "    # Equation 11 in the paper\n",
        "    # Use our model (noise predictor) to predict the mean\n",
        "    model_mean = sqrt_recip_alphas_t * (\n",
        "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
        "    )\n",
        "\n",
        "    if t_index == 0:\n",
        "        return model_mean\n",
        "    else:\n",
        "        posterior_variance_t = extract(posterior_variance, t, x.shape)\n",
        "        noise = torch.randn_like(x)\n",
        "        # Algorithm 2 line 4:\n",
        "        return model_mean + torch.sqrt(posterior_variance_t) * noise\n",
        "\n",
        "# Algorithm 2 but save all images:\n",
        "@torch.no_grad()\n",
        "def p_sample_loop(model, shape):\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    b = shape[0]\n",
        "    # start from pure noise (for each example in the batch)\n",
        "    img = torch.randn(shape, device=device)\n",
        "    imgs = []\n",
        "\n",
        "    for i in tqdm(reversed(range(0, timesteps)), desc='sampling loop time step', total=timesteps):\n",
        "        img = p_sample(model, img, torch.full((b,), i, device=device, dtype=torch.long), i)\n",
        "        imgs.append(img.cpu().numpy())\n",
        "    return imgs\n",
        "\n",
        "@torch.no_grad()\n",
        "def sample(model, image_size, batch_size=16, channels=3):\n",
        "    return p_sample_loop(model, shape=(batch_size, channels, image_size, image_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f70235f8",
      "metadata": {
        "id": "f70235f8"
      },
      "source": [
        "\n",
        "Note that the code above is a simplified version of the original implementation. We found our simplification (which is in line with Algorithm 2 in the paper) to work just as well as the [original, more complex implementation](https://github.com/hojonathanho/diffusion/blob/master/diffusion_tf/diffusion_utils.py).\n",
        "\n",
        "\n",
        "## Train the model\n",
        "\n",
        "Next, we train the model in regular PyTorch fashion. We also define some logic to peridiocally save generated images, using the `sample` method defined above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0c1ad663",
      "metadata": {
        "id": "0c1ad663"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def num_to_groups(num, divisor):\n",
        "    groups = num // divisor\n",
        "    remainder = num % divisor\n",
        "    arr = [divisor] * groups\n",
        "    if remainder > 0:\n",
        "        arr.append(remainder)\n",
        "    return arr\n",
        "\n",
        "results_folder = Path(\"./results\")\n",
        "results_folder.mkdir(exist_ok = True)\n",
        "save_and_sample_every = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22e4c0fd",
      "metadata": {
        "id": "22e4c0fd"
      },
      "source": [
        "Below, we define the model, and move it to the GPU. We also define a standard optimizer (Adam)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "a5126e21",
      "metadata": {
        "id": "a5126e21"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = Unet(\n",
        "    dim=image_size,\n",
        "    channels=channels,\n",
        "    dim_mults=(1, 2, 4,)\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=0.5e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7444b0b",
      "metadata": {
        "id": "f7444b0b"
      },
      "source": [
        "Let's start training!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss = float('inf')\n",
        "best_model_path = results_folder / 'best_model.pth'\n",
        "epochs = 2"
      ],
      "metadata": {
        "id": "E8lzA2p5thbk"
      },
      "id": "E8lzA2p5thbk",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92b12ed1",
      "metadata": {
        "id": "92b12ed1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b02751a-9192-4427-a149-e2c3bb733b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.47131025791168213\n"
          ]
        }
      ],
      "source": [
        "from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for step, batch in enumerate(dataloader):\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      batch_size = batch[\"pixel_values\"].shape[0]\n",
        "      batch = batch[\"pixel_values\"].to(device)\n",
        "\n",
        "      # Algorithm 1 line 3: sample t uniformally for every example in the batch\n",
        "      t = torch.randint(0, timesteps, (batch_size,), device=device).long()\n",
        "\n",
        "      loss = p_losses(model, batch, t, loss_type=\"huber\")\n",
        "\n",
        "      if step % 100 == 0:\n",
        "        print(\"Loss:\", loss.item())\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # save generated images\n",
        "      if step != 0 and step % save_and_sample_every == 0:\n",
        "        milestone = step // save_and_sample_every\n",
        "        batches = num_to_groups(4, batch_size)\n",
        "        all_images_list = list(map(lambda n: sample(model, batch_size=n, channels=channels), batches))\n",
        "        all_images = torch.cat(all_images_list, dim=0)\n",
        "        all_images = (all_images + 1) * 0.5\n",
        "        save_image(all_images, str(results_folder / f'sample-{milestone}.png'), nrow = 6)\n",
        "\n",
        "      if loss.item() < best_loss:\n",
        "          best_loss = loss.item()\n",
        "          # Save the current best model\n",
        "          torch.save(model.state_dict(), str(best_model_path))\n",
        "    print(f'Epoch: {epoch} done')\n",
        "print(\"Training complete. Best model saved at:\", best_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e617a66a",
      "metadata": {
        "id": "e617a66a"
      },
      "source": [
        "<div class=\"output stream stdout\">\n",
        "\n",
        "    Output:\n",
        "    ----------------------------------------------------------------------------------------------------\n",
        "    Loss: 0.4983023405075073\n",
        "    Loss: 0.39801889657974243\n",
        "    Loss: 0.0736956000328064\n",
        "    Loss: 0.07393301278352737\n",
        "    Loss: 0.061900846660137177\n",
        "    Loss: 0.05622437596321106\n",
        "    Loss: 0.06978295743465424\n",
        "    Loss: 0.05728264898061752\n",
        "    Loss: 0.04997706413269043\n",
        "    Loss: 0.04280048608779907\n",
        "    Loss: 0.0727246031165123\n",
        "    Loss: 0.05297926068305969\n",
        "    Loss: 0.05409959703683853\n",
        "    Loss: 0.04747987166047096\n",
        "    Loss: 0.035598237067461014\n",
        "    Loss: 0.0527019277215004\n",
        "    Loss: 0.07990720868110657\n",
        "    Loss: 0.054530248045921326\n",
        "    Loss: 0.055565401911735535\n",
        "    Loss: 0.06428372114896774\n",
        "    Loss: 0.04885242134332657\n",
        "    Loss: 0.03893771022558212\n",
        "    Loss: 0.051399704068899155\n",
        "    Loss: 0.057855039834976196\n",
        "    Loss: 0.04714621976017952\n",
        "    Loss: 0.03357722982764244\n",
        "    Loss: 208.99063110351562\n",
        "    Loss: 9.244522094726562\n",
        "    Loss: 0.5289267301559448\n",
        "    Loss: 0.5148600339889526\n",
        "    Loss: 0.4702889919281006\n",
        "    Loss: 0.46772074699401855\n",
        "    Loss: 0.44204193353652954\n",
        "    Loss: 0.45206841826438904\n",
        "    Loss: 0.4416607916355133\n",
        "    Loss: 0.4336085915565491\n",
        "    Loss: 0.43263787031173706\n",
        "    Loss: 0.4376640319824219\n",
        "    Loss: 0.441015362739563\n",
        "    Loss: 0.43330106139183044\n",
        "    Loss: 0.43023940920829773\n",
        "    Loss: 0.4529106318950653\n",
        "    Loss: 0.4243009686470032\n",
        "    Loss: 0.43362975120544434\n",
        "    Loss: 0.427144855260849\n",
        "    Loss: 0.42477086186408997\n",
        "    Loss: 0.4267113208770752\n",
        "    Loss: 0.4268029034137726\n",
        "    Loss: 0.42597129940986633\n",
        "    Loss: 0.4220198392868042\n",
        "    Loss: 0.41900452971458435\n",
        "    Loss: 0.4279913306236267\n",
        "    Loss: 0.42393946647644043\n",
        "    Loss: 0.4201338291168213\n",
        "    Loss: 0.42008107900619507\n",
        "    Loss: 0.4240165948867798\n",
        "    Loss: 0.42016369104385376\n",
        "    Loss: 0.41972240805625916\n",
        "    Loss: 0.420395165681839\n",
        "    Loss: 0.421099990606308\n",
        "\n",
        "</div>\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = Unet(\n",
        "    dim=image_size,\n",
        "    channels=channels,\n",
        "    dim_mults=(1, 2, 4,)\n",
        ")\n",
        "best_model.load_state_dict(torch.load(str(best_model_path)))\n",
        "best_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjJCgpbZtosj",
        "outputId": "89eba4e3-056d-4982-dcad-cdfb53e27e2b"
      },
      "id": "tjJCgpbZtosj",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unet(\n",
              "  (init_conv): Conv2d(3, 42, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "  (time_mlp): Sequential(\n",
              "    (0): SinusoidalPositionEmbeddings()\n",
              "    (1): Linear(in_features=64, out_features=256, bias=True)\n",
              "    (2): GELU(approximate='none')\n",
              "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (downs): ModuleList(\n",
              "    (0): ModuleList(\n",
              "      (0): ConvNextBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): GELU(approximate='none')\n",
              "          (1): Linear(in_features=256, out_features=42, bias=True)\n",
              "        )\n",
              "        (ds_conv): Conv2d(42, 42, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=42)\n",
              "        (net): Sequential(\n",
              "          (0): GroupNorm(1, 42, eps=1e-05, affine=True)\n",
              "          (1): Conv2d(42, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (res_conv): Conv2d(42, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (1): ConvNextBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): GELU(approximate='none')\n",
              "          (1): Linear(in_features=256, out_features=64, bias=True)\n",
              "        )\n",
              "        (ds_conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
              "        (net): Sequential(\n",
              "          (0): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
              "          (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (res_conv): Identity()\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (fn): LinearAttention(\n",
              "            (to_qkv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
              "            )\n",
              "          )\n",
              "          (norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
              "        )\n",
              "      )\n",
              "      (3): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    )\n",
              "    (1): ModuleList(\n",
              "      (0): ConvNextBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): GELU(approximate='none')\n",
              "          (1): Linear(in_features=256, out_features=64, bias=True)\n",
              "        )\n",
              "        (ds_conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
              "        (net): Sequential(\n",
              "          (0): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
              "          (1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
              "          (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (res_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (1): ConvNextBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): GELU(approximate='none')\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (ds_conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
              "        (net): Sequential(\n",
              "          (0): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
              "          (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (res_conv): Identity()\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (fn): LinearAttention(\n",
              "            (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "            )\n",
              "          )\n",
              "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "        )\n",
              "      )\n",
              "      (3): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    )\n",
              "    (2): ModuleList(\n",
              "      (0): ConvNextBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): GELU(approximate='none')\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (ds_conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
              "        (net): Sequential(\n",
              "          (0): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          (1): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
              "          (4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (res_conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (1): ConvNextBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): GELU(approximate='none')\n",
              "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (ds_conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
              "        (net): Sequential(\n",
              "          (0): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
              "          (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
              "          (4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (res_conv): Identity()\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (fn): LinearAttention(\n",
              "            (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
              "            )\n",
              "          )\n",
              "          (norm): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
              "        )\n",
              "      )\n",
              "      (3): Identity()\n",
              "    )\n",
              "  )\n",
              "  (ups): ModuleList(\n",
              "    (0): ModuleList(\n",
              "      (0): ConvNextBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): GELU(approximate='none')\n",
              "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
              "        )\n",
              "        (ds_conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
              "        (net): Sequential(\n",
              "          (0): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
              "          (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
              "          (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (res_conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (1): ConvNextBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): GELU(approximate='none')\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (ds_conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
              "        (net): Sequential(\n",
              "          (0): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
              "          (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (res_conv): Identity()\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (fn): LinearAttention(\n",
              "            (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "            )\n",
              "          )\n",
              "          (norm): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "        )\n",
              "      )\n",
              "      (3): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    )\n",
              "    (1): ModuleList(\n",
              "      (0): ConvNextBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): GELU(approximate='none')\n",
              "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (ds_conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
              "        (net): Sequential(\n",
              "          (0): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
              "          (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (res_conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (1): ConvNextBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): GELU(approximate='none')\n",
              "          (1): Linear(in_features=256, out_features=64, bias=True)\n",
              "        )\n",
              "        (ds_conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
              "        (net): Sequential(\n",
              "          (0): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
              "          (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (2): GELU(approximate='none')\n",
              "          (3): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (res_conv): Identity()\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (fn): LinearAttention(\n",
              "            (to_qkv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
              "            )\n",
              "          )\n",
              "          (norm): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
              "        )\n",
              "      )\n",
              "      (3): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (mid_block1): ConvNextBlock(\n",
              "    (mlp): Sequential(\n",
              "      (0): GELU(approximate='none')\n",
              "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "    )\n",
              "    (ds_conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
              "    (net): Sequential(\n",
              "      (0): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
              "      (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (2): GELU(approximate='none')\n",
              "      (3): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
              "      (4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "    (res_conv): Identity()\n",
              "  )\n",
              "  (mid_attn): Residual(\n",
              "    (fn): PreNorm(\n",
              "      (fn): Attention(\n",
              "        (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (to_out): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (norm): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
              "    )\n",
              "  )\n",
              "  (mid_block2): ConvNextBlock(\n",
              "    (mlp): Sequential(\n",
              "      (0): GELU(approximate='none')\n",
              "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "    )\n",
              "    (ds_conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
              "    (net): Sequential(\n",
              "      (0): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
              "      (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (2): GELU(approximate='none')\n",
              "      (3): GroupNorm(1, 512, eps=1e-05, affine=True)\n",
              "      (4): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "    (res_conv): Identity()\n",
              "  )\n",
              "  (final_conv): Sequential(\n",
              "    (0): ConvNextBlock(\n",
              "      (ds_conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
              "      (net): Sequential(\n",
              "        (0): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
              "        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (2): GELU(approximate='none')\n",
              "        (3): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "        (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (res_conv): Identity()\n",
              "    )\n",
              "    (1): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8337c82",
      "metadata": {
        "id": "a8337c82"
      },
      "source": [
        "## Sampling (inference)\n",
        "\n",
        "To sample from the model, we can just use our sample function defined above:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "f3d8a814",
      "metadata": {
        "id": "f3d8a814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2e468a1fbb4c4a3f80ca6bad2720043c",
            "d23321d9ac2b4c399f20cdddd0ea2688",
            "af935cf1064e45b78425d98b1d255ffa",
            "8653e97309884727ab32ac16dc574412",
            "d364cdc08ec74914a9c9a5b4ece06e94",
            "577b2705b225435a86a1d746f66b5461",
            "1c99e245a714490fae6340664e03de07",
            "af71c074233646dd868be319274beac2",
            "79c280fa50a74037aa244abab90eed03",
            "71cf29717377498ea573cfadce3cebd0",
            "bf912d268956461fa73ea5fefca09d2e"
          ]
        },
        "outputId": "18a246e7-8742-4333-f6c0-6c27399d1d7a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sampling loop time step:   0%|          | 0/200 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e468a1fbb4c4a3f80ca6bad2720043c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# sample 64 images\n",
        "samples = sample(model, image_size=image_size, batch_size=64, channels=channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "_s-Al2lJ2c8T",
      "metadata": {
        "id": "_s-Al2lJ2c8T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "25c6c44c-f0d8-4f7b-c501-8fa265f9c6e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a07b0daba00>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# show a random one\n",
        "random_index = 5\n",
        "plt.imshow(samples[-1][random_index].reshape(image_size, image_size, channels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples[-1][random_index].shape"
      ],
      "metadata": {
        "id": "-7gn34yWubLM"
      },
      "id": "-7gn34yWubLM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0k4H1fmlKvzR",
      "metadata": {
        "id": "0k4H1fmlKvzR"
      },
      "source": [
        "Seems like the model is capable of generating a nice T-shirt! Keep in mind that the dataset we trained on is pretty low-resolution (28x28).\n",
        "\n",
        "We can also create a gif of the denoising process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "spE1I9aVNwzZ",
      "metadata": {
        "id": "spE1I9aVNwzZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.animation as animation\n",
        "\n",
        "random_index = 53\n",
        "\n",
        "fig = plt.figure()\n",
        "ims = []\n",
        "for i in range(timesteps):\n",
        "    im = plt.imshow(samples[i][random_index].reshape(image_size, image_size, channels), cmap=\"gray\", animated=True)\n",
        "    ims.append([im])\n",
        "\n",
        "animate = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
        "animate.save('diffusion.gif')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b02eb802",
      "metadata": {
        "id": "b02eb802"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1eyonQWhfmbQsTq8ndsNjw5QSRQ9em9Au\" width=\"500\" />\n",
        "\n",
        "# Follow-up reads\n",
        "\n",
        "Note that the DDPM paper showed that diffusion models are a promising direction for (un)conditional image generation. This has since then (immensely) been improved, most notably for text-conditional image generation. Below, we list some important (but far from exhaustive) follow-up works:\n",
        "\n",
        "- Improved Denoising Diffusion Probabilistic Models ([Nichol et al., 2021](https://arxiv.org/abs/2102.09672)): finds that learning the variance of the conditional distribution (besides the mean) helps in improving performance\n",
        "- Cascaded Diffusion Models for High Fidelity Image Generation ([Ho et al., 2021](https://arxiv.org/abs/2106.15282)): introduce cascaded diffusion, which comprises a pipeline of multiple diffusion models that generate images of increasing resolution for high-fidelity image synthesis\n",
        "- Diffusion Models Beat GANs on Image Synthesis ([Dhariwal et al., 2021](https://arxiv.org/abs/2105.05233)): show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models by improving the U-Net architecture, as well as introducing classifier guidance\n",
        "- Classifier-Free Diffusion Guidance ([Ho et al., 2021](https://openreview.net/pdf?id=qw8AKxfYbI)): shows that you don't need a classifier for guiding a diffusion model by jointly training a conditional and an unconditional diffusion model with a single neural network\n",
        "- Hierarchical Text-Conditional Image Generation with CLIP Latents (DALL-E 2) ([Ramesh et al., 2022](https://cdn.openai.com/papers/dall-e-2.pdf)): use a prior to turn a text caption into a CLIP image embedding, after which a diffusion model decodes it into an image\n",
        "- Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding (ImageGen) ([Saharia et al., 2022](https://arxiv.org/abs/2205.11487)): shows that combining a large pre-trained language model (e.g. T5) with cascaded diffusion works well for text-to-image synthesis\n",
        "\n",
        "Note that this list only includes important works until the time of writing, which is June 7th, 2022.\n",
        "\n",
        "For now, it seems that the main (perhaps only) disadvantage of diffusion models is that they require multiple forward passes to generate an image (which is not the case for generative models like GANs). However, there's [research going on](https://arxiv.org/abs/2204.13902) that enables high-fidelity generation in as few as 10 denoising steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YinXsM62JYjn",
      "metadata": {
        "id": "YinXsM62JYjn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6fe49a34",
        "f70235f8",
        "b02eb802"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01423017e024419ebbb80e4c43cf0216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa27118af23a41bcadd3c6796eb5ecf7",
              "IPY_MODEL_cff8b07a6fa14c0aa87fa3fb5afe2ac9",
              "IPY_MODEL_2130d822372f4f6abb03291e92fa546f"
            ],
            "layout": "IPY_MODEL_ed4d02e7561f40ba973a264c219e1657"
          }
        },
        "fa27118af23a41bcadd3c6796eb5ecf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b3ef2a6609c46fbb958712fd82cdabc",
            "placeholder": "​",
            "style": "IPY_MODEL_df1f1599429c4c96a97b03e2ff14742b",
            "value": "Resolving data files: 100%"
          }
        },
        "cff8b07a6fa14c0aa87fa3fb5afe2ac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0e2655a62e3453dad032f81423eea73",
            "max": 8189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_098352c2ee3245d790434d5c5f482421",
            "value": 8189
          }
        },
        "2130d822372f4f6abb03291e92fa546f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0ee8fbec972496f9fdd1fc95861fe80",
            "placeholder": "​",
            "style": "IPY_MODEL_77af21838d95434db3d7eb2fad44b69d",
            "value": " 8189/8189 [00:00&lt;00:00, 141148.25it/s]"
          }
        },
        "ed4d02e7561f40ba973a264c219e1657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b3ef2a6609c46fbb958712fd82cdabc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df1f1599429c4c96a97b03e2ff14742b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0e2655a62e3453dad032f81423eea73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "098352c2ee3245d790434d5c5f482421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0ee8fbec972496f9fdd1fc95861fe80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77af21838d95434db3d7eb2fad44b69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4f5ff81658f43139a88f7616c438c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d9c076fb8d047daafa521757335d2d7",
              "IPY_MODEL_0dd051afc771499383d366ac29ff976d",
              "IPY_MODEL_44b1cc5bfd254c8794f52883f8fdc279"
            ],
            "layout": "IPY_MODEL_3b048c588f3d4100bf2d0d0c90335075"
          }
        },
        "1d9c076fb8d047daafa521757335d2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f31f793fa24bd19301b8a3c321309d",
            "placeholder": "​",
            "style": "IPY_MODEL_8e262e626e434fa395f9e3099c3a1712",
            "value": "Downloading data files: 100%"
          }
        },
        "0dd051afc771499383d366ac29ff976d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40690a7058eb457182d545be7cb9b4e0",
            "max": 8189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d5a4ca2352e4fe281a5e85d7e9ae4ff",
            "value": 8189
          }
        },
        "44b1cc5bfd254c8794f52883f8fdc279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_063d5d8b3fc0422f908700f0c0ccd186",
            "placeholder": "​",
            "style": "IPY_MODEL_6389c17ce7474602963842db2d6cce64",
            "value": " 8189/8189 [00:00&lt;00:00, 56938.38it/s]"
          }
        },
        "3b048c588f3d4100bf2d0d0c90335075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f31f793fa24bd19301b8a3c321309d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e262e626e434fa395f9e3099c3a1712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40690a7058eb457182d545be7cb9b4e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d5a4ca2352e4fe281a5e85d7e9ae4ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "063d5d8b3fc0422f908700f0c0ccd186": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6389c17ce7474602963842db2d6cce64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b438025e252405494bc05e25e4cf28d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d6f3798d16c4c4c9d4f4aa2374ccd16",
              "IPY_MODEL_371827e54f7c4289a26ffb2c471d5598",
              "IPY_MODEL_9b66ba475a3248cf81fe85a4ae44abc7"
            ],
            "layout": "IPY_MODEL_10294d6e329948d5864a28f8a846bd8f"
          }
        },
        "6d6f3798d16c4c4c9d4f4aa2374ccd16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2c2b425886e40138880dc2d0bc2f610",
            "placeholder": "​",
            "style": "IPY_MODEL_3c31c17cb2c545f0b311c3f498c11472",
            "value": "Downloading data files: "
          }
        },
        "371827e54f7c4289a26ffb2c471d5598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80223ccb8f6543819fe25559339bf363",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_279b0b0c4ab1424d8ea24cb95aa1878a",
            "value": 0
          }
        },
        "9b66ba475a3248cf81fe85a4ae44abc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21811134f0114bd0aa9e112c1cbad590",
            "placeholder": "​",
            "style": "IPY_MODEL_6d223f5cf4034a338e3dd0d07f70e236",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "10294d6e329948d5864a28f8a846bd8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2c2b425886e40138880dc2d0bc2f610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c31c17cb2c545f0b311c3f498c11472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80223ccb8f6543819fe25559339bf363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "279b0b0c4ab1424d8ea24cb95aa1878a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21811134f0114bd0aa9e112c1cbad590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d223f5cf4034a338e3dd0d07f70e236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5db064820ab7471b828396e7a024ca5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4517b28ccd44809983b3456c8308001",
              "IPY_MODEL_8a4b2ccaef7b4512b8f46fb996a00216",
              "IPY_MODEL_c29c34a2f27947089c4769375aed7598"
            ],
            "layout": "IPY_MODEL_52cab01533d24ff684529a3eb23e19f7"
          }
        },
        "c4517b28ccd44809983b3456c8308001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fbca02247b44e2285f8d7e60d7727e6",
            "placeholder": "​",
            "style": "IPY_MODEL_188ff26dad9041e7b778ca90188f3970",
            "value": "Extracting data files: "
          }
        },
        "8a4b2ccaef7b4512b8f46fb996a00216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37520fc4802d40a78fc6860f215161d6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aef9c58ae4a54f84b23ac00107e42a0a",
            "value": 0
          }
        },
        "c29c34a2f27947089c4769375aed7598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12f1e7f4456f4decbcbcb23f8cb110aa",
            "placeholder": "​",
            "style": "IPY_MODEL_f3654cd797984731b2cb1d4b3a06b2e1",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "52cab01533d24ff684529a3eb23e19f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fbca02247b44e2285f8d7e60d7727e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "188ff26dad9041e7b778ca90188f3970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37520fc4802d40a78fc6860f215161d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "aef9c58ae4a54f84b23ac00107e42a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12f1e7f4456f4decbcbcb23f8cb110aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3654cd797984731b2cb1d4b3a06b2e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ebf87c9aa92432b9b76e0c27d70850e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_341f6cd5272e40b884212c561068806a",
              "IPY_MODEL_83beead9fd504de7a2334acf37bfb2b5",
              "IPY_MODEL_ce0ba74d4cb94a5285bb36fd783396cc"
            ],
            "layout": "IPY_MODEL_9e290f6900d1402ab0b5e08fa2cb7666"
          }
        },
        "341f6cd5272e40b884212c561068806a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1514aa78ae0746569ab95efb1fe7f464",
            "placeholder": "​",
            "style": "IPY_MODEL_b566c65dfb0849d98e294f65c0685c9a",
            "value": "Generating train split: "
          }
        },
        "83beead9fd504de7a2334acf37bfb2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_511bef34fce647fcb50a5d9aa9283f40",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f0cb0bf4cfb4f4f9ed01a3cfa208ea0",
            "value": 1
          }
        },
        "ce0ba74d4cb94a5285bb36fd783396cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00251177652c485c9da8f809c699a881",
            "placeholder": "​",
            "style": "IPY_MODEL_af6448f18db2453f9556ae682b0d85f9",
            "value": " 8189/0 [00:00&lt;00:00, 12972.57 examples/s]"
          }
        },
        "9e290f6900d1402ab0b5e08fa2cb7666": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1514aa78ae0746569ab95efb1fe7f464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b566c65dfb0849d98e294f65c0685c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "511bef34fce647fcb50a5d9aa9283f40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9f0cb0bf4cfb4f4f9ed01a3cfa208ea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00251177652c485c9da8f809c699a881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af6448f18db2453f9556ae682b0d85f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e468a1fbb4c4a3f80ca6bad2720043c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d23321d9ac2b4c399f20cdddd0ea2688",
              "IPY_MODEL_af935cf1064e45b78425d98b1d255ffa",
              "IPY_MODEL_8653e97309884727ab32ac16dc574412"
            ],
            "layout": "IPY_MODEL_d364cdc08ec74914a9c9a5b4ece06e94"
          }
        },
        "d23321d9ac2b4c399f20cdddd0ea2688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_577b2705b225435a86a1d746f66b5461",
            "placeholder": "​",
            "style": "IPY_MODEL_1c99e245a714490fae6340664e03de07",
            "value": "sampling loop time step: 100%"
          }
        },
        "af935cf1064e45b78425d98b1d255ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af71c074233646dd868be319274beac2",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79c280fa50a74037aa244abab90eed03",
            "value": 200
          }
        },
        "8653e97309884727ab32ac16dc574412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71cf29717377498ea573cfadce3cebd0",
            "placeholder": "​",
            "style": "IPY_MODEL_bf912d268956461fa73ea5fefca09d2e",
            "value": " 200/200 [00:46&lt;00:00,  4.30it/s]"
          }
        },
        "d364cdc08ec74914a9c9a5b4ece06e94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "577b2705b225435a86a1d746f66b5461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c99e245a714490fae6340664e03de07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af71c074233646dd868be319274beac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79c280fa50a74037aa244abab90eed03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71cf29717377498ea573cfadce3cebd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf912d268956461fa73ea5fefca09d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}